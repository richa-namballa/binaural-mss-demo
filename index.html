---
layout: page
gh-repo: richa-namballa/mss-demo
gh-badge: [star, watch, fork, follow]
share-description: Musical Source Separation of Brazilian Percussion
---

<head>
    <title>Do Music Source Separation Models Preserve Spatial Information in Binaural Audio?</title>
</head>

<body>
    <div class="overlay"></div>
    <div class="container">
        <div class="row">
            <div class="col-xl-12 mx-auto text-center">
                <h1>Do Music Source Separation Models Preserve Spatial Information in Binaural Audio?</h1>
            </div>
            <div class="col-md-10 col-lg-8 col-xl-7 mx-auto">
            </div>
        </div>
    </div>

    <div class="container-fluid">
        <section class="testimonials text-center">
            <div class="row justify-content-center">
                <div class="col-lg-4 text-center">
                    <div class="testimonial-item mx-auto">
                        <h4 style="white-space: nowrap;">
                            <a href="https://steinhardt.nyu.edu/people/richa-namballa" style="text-decoration: none;">
                                Richa Namballa
                            </a>
                        </h4>
                        <p><a href="mailto:rn2214@nyu.edu">rn2214@nyu.edu</a></p>
                        <p>Music Technology<br>New York University<br>New York City, USA</p>
                    </div>
                </div>
                <!-- Giovana Morais -->
                <div class="col-lg-4 text-center">
                    <div class="testimonial-item mx-auto">
                        <h4 style="white-space: nowrap;">
                            <a href="https://steinhardt.nyu.edu/people/agnieszka-roginska" style="text-decoration: none;">
                                Agnieszka Roginska
                            </a>
                        </h4>
                        <p><a href="mailto:ar137@nyu.edu">ar137@nyu.edu</a></p>
                        <p>Music Technology<br>New York University<br>New York City, USA</p>
                    </div>
                </div>

                <!-- Magdalena Fuentes -->
                <div class="col-lg-4 text-center">
                    <div class="testimonial-item mx-auto">
                        <h4 style="white-space: nowrap;">
                            <a href="https://steinhardt.nyu.edu/people/magdalena-fuentes"
                                style="text-decoration: none;">
                                Magdalena Fuentes
                            </a>
                        </h4>
                        <p><a href="mailto:mf3734@nyu.edu">mf3734@nyu.edu</a></p>
                        <p>Music Technology / IDM<br>New York University,<br>New York City, USA</p>
                    </div>
                </div>
            </div>
        </section>
    </div>

    <br>
    <h5 class="mx-auto text-center" style="color: black">Accepted at ISMIR 2025</h5>

        <br>
    <h4 class="mx-auto text-center" style="color: black"><a href="https://arxiv.org/abs/2507.00155">[PDF]</a> 
        <!-- <a href="assets/pdf/490_poster.pdf">[Poster]</a></h4> -->

    </h4>
    </div>

    <br>
    <h3 style="text-align: center">Summary</h3>
    <p class="lead mb-0" align="justify" style="padding-bottom: 20px;">
    Binaural audio remains underexplored within the music information retrieval community. Motivated by the rising popularity of virtual and augmented reality experiences as well as potential applications to accessibility, we investigate how well existing music source separation (MSS) models perform on binaural audio. Although these models process two-channel inputs, it is unclear how effectively they retain spatial information. In this work, we evaluate how several popular MSS models preserve spatial information on both standard stereo and novel binaural datasets. Our binaural data is synthesized using stems from MUSDB18-HQ and open-source head-related transfer functions by positioning instrument sources randomly along the horizontal plane. We then assess the spatial quality of the separated stems using signal processing and interaural cue-based metrics. Our results show that stereo MSS models fail to preserve  the spatial information critical for maintaining the immersive quality of binaural audio, and that the degradation depends on model architecture as well as the target instrument. Finally, we highlight valuable opportunities for future work at the intersection of MSS and immersive audio.
    </p>
    <br>

    <br>
    <h3 style="text-align: center; padding-bottom: 20px;">Audio Examples</h3>

</body>